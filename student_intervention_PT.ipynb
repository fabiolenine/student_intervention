{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizagem Supervisionada\n",
    "## Project 2: Construindo um Sistema de Intervenção para Estudantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem-vindo ao segundo projeto do Nanodegree de Machine Learning! Neste Notebook, alguns templates de código já foram fornecidos, e será o seu trabalho implementar funcionalidades necessárias para completar este projeto com êxito. Seções que começam com **'Implementação'** no cabeçalho indicam que o bloco de código que se segue precisará de funcionalidades adicionais que você deve fornecer. Instruções serão providenciadas para cada seção e as especificações para cada implementação estarão marcadas no bloco de código com o comando `'TODO'`. Tenha certeza de ler atentamente todas as instruções!\n",
    "\n",
    "Além do código implementado, haverá questões relacionadas ao projeto e à implementação que você deve responder. Cada seção em que você tem que responder uma questão será antecedida de um cabeçalho **'Questão X'**. Leia atentamente cada questão e escreva respostas completas nas caixas de texto subsequentes que começam com **'Resposta: '**. O projeto enviado será avaliado baseado nas respostas para cada questão e a implementação que você forneceu.  \n",
    "\n",
    ">**Nota:** Células de código e Markdown podem ser executadas utilizando o atalho de teclado **Shift + Enter**. Além disso, as células Markdown podem ser editadas, um clique duplo na célula entra no modo de edição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Classificação versus Regressão\n",
    "*Seu objetivo neste projeto é identificar estudantes que possam precisar de intervenção antecipada antes de serem reprovados. Que tipo de problema de aprendizagem supervisionada é esse: classificação ou regressão? Por quê?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** É do tipo classificação. Pois a regressão é usada para prever valores, que não é o caso. Desta forma, o problema é adequado para classificacão porque o objetivo é identificar alunos que possui caracteristicas que os fará reprovar. \n",
    "Em outras palavras, o atributo alvo possuem rótulos (ou classes), os quais essas assumem valores discretos, desta forma podemos perceber que se trata de classificação. Se, por outro lado, o atributo alvo contivesse valores numéricos contínuos, teriamos um problema do tipo regressão.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observando os Dados\n",
    "Execute a célula de código abaixo para carregar as bibliotecas de Python necessárias e os dados sobre os estudantes. Note que a última coluna desse conjunto de dados, `'passed'`, será nosso rótulo alvo (se o aluno foi ou não aprovado). As outras colunas são atributos sobre cada aluno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados dos estudantes foram lidos com êxito!\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "   ...   internet romantic  famrel  freetime  goout Dalc Walc health absences  \\\n",
      "0  ...         no       no       4         3      4    1    1      3        6   \n",
      "1  ...        yes       no       5         3      3    1    1      3        4   \n",
      "2  ...        yes       no       4         3      2    2    3      3       10   \n",
      "3  ...        yes      yes       3         2      2    1    1      5        2   \n",
      "4  ...         no       no       4         3      2    1    2      5        4   \n",
      "\n",
      "  passed  \n",
      "0     no  \n",
      "1     no  \n",
      "2    yes  \n",
      "3    yes  \n",
      "4    yes  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "(395, 31)\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "from numba import autojit\n",
    "\n",
    "# Ler os dados dos estudantes\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Os dados dos estudantes foram lidos com êxito!\"\n",
    "print student_data.head()\n",
    "print student_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Observando os Dados\n",
    "Vamos começar observando o conjunto de dados para determinar quantos são os estudantes sobre os quais temos informações e entender a taxa de graduação entre esses estudantes. Na célula de código abaixo, você vai precisar calcular o seguinte:\n",
    "- O número total de estudantes, `n_students`.\n",
    "- O número total de atributos para cada estudante, `n_features`.\n",
    "- O número de estudantes aprovados, `n_passed`.\n",
    "- O número de estudantes reprovados, `n_failed`.\n",
    "- A taxa de graduação da classe, `grad_rate`, em porcentagem (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de estudantes: 394\n",
      "Número de atributos: 30\n",
      "Número de estudantes aprovados: 265\n",
      "Número de estudantes reprovados: 130\n",
      "Taxa de graduação: 67.26%\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "# TODO: Calcule o número de estudante\n",
    "n_students = student_data.shape[0] -1\n",
    "\n",
    "# TODO: Calcule o número de atributos\n",
    "n_features = student_data.columns[:-1].size\n",
    "\n",
    "# TODO: Calcule o número de alunos aprovados\n",
    "n_passed = student_data.passed.value_counts()['yes']\n",
    "\n",
    "# TODO: Calcule o número de alunos reprovados\n",
    "n_failed = student_data.passed.value_counts()['no']\n",
    "\n",
    "# TODO: Calcule a taxa de graduação\n",
    "grad_rate = n_passed/n_students*100\n",
    "\n",
    "# Imprima os resultados\n",
    "print \"Número total de estudantes: {}\".format(n_students)\n",
    "print \"Número de atributos: {}\".format(n_features)\n",
    "print \"Número de estudantes aprovados: {}\".format(n_passed)\n",
    "print \"Número de estudantes reprovados: {}\".format(n_failed)\n",
    "print \"Taxa de graduação: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Dados\n",
    "Nesta seção, vamos preparara os dados para modelagem, treinamento e teste.\n",
    "\n",
    "### Identificar atributos e variáveis-alvo\n",
    "É comum que os dados que você obteve contenham atributos não numéricos. Isso pode ser um problema, dado que a maioria dos algoritmos de machine learning esperam dados númericos para operar cálculos.\n",
    "\n",
    "Execute a célula de código abaixo para separar os dados dos estudantes em atributos e variáveis-alvo e verificar se algum desses atributos é não numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de atributos:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Coluna-alvo: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extraia as colunas dos atributo\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "# Extraia a coluna-alvo, 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Mostre a lista de colunas\n",
    "print \"Colunas de atributos:\\n{}\".format(feature_cols)\n",
    "print \"\\nColuna-alvo: {}\".format(target_col)\n",
    "\n",
    "# Separe os dados em atributos e variáveis-alvo (X_all e y_all, respectivamente)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Mostre os atributos imprimindo as cinco primeiras linhas\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processar Colunas de Atributo\n",
    "\n",
    "Como você pode ver, há muitas colunas não numéricas que precisam ser convertidas! Muitas delas são simplesmente `yes`/`no`, por exemplo, a coluna `internet`. É razoável converter essas variáveis em valores (binários) `1`/`0`.\n",
    "\n",
    "Outras colunas, como `Mjob` e `Fjob`, têm mais do que dois valores e são conhecidas como variáveis categóricas. A maneira recomendada de lidar com esse tipo de coluna é criar uma quantidade de colunas proporcional aos possíveis valores (por exemplo, `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc), e assinalar `1` para um deles e `0` para todos os outros.\n",
    "\n",
    "Essas colunas geradas são por vezes chamadas de _variáveis postiças_ (em inglês: _dummy variables_), e nós iremos utilizar a função [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para fazer essa conversão. Execute a célula de código abaixo para executar a rotina de pré-processamento discutida nesta seção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "@autojit\n",
    "def preprocess_features(X):\n",
    "    ''' Pré-processa os dados dos estudantes e converte as variáveis binárias não numéricas em\n",
    "        variáveis binárias (0/1). Converte variáveis categóricas em variáveis postiças. '''\n",
    "    \n",
    "    # Inicialize nova saída DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Observe os dados em cada coluna de atributos \n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # Se o tipo de dado for não numérico, substitua todos os valores yes/no por 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # Se o tipo de dado for categórico, converta-o para uma variável dummy\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Reúna as colunas revisadas\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Divisão dos Dados de Treinamento e Teste\n",
    "Até agora, nós convertemos todos os atributos _categóricos_ em valores numéricos. Para o próximo passo, vamos dividir os dados (tanto atributos como os rótulos correspondentes) em conjuntos de treinamento e teste. Na célula de código abaixo, você irá precisar implementar o seguinte:\n",
    "- Embaralhe aleatoriamente os dados (`X_all`, `y_all`) em subconjuntos de treinamento e teste.\n",
    "  - Utilizar 300 pontos de treinamento (aproxidamente 75%) e 95 pontos de teste (aproximadamente 25%).\n",
    "  - Estabelecer um `random_state` para as funções que você utiliza, se a opção existir.\n",
    "  - Armazene os resultados em `X_train`, `X_test`, `y_train` e `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento tem 300 amostras.\n",
      "O conjunto de teste tem 95 amostras.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiolenine/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe qualquer funcionalidade adicional de que você possa precisar aqui\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# TODO: Estabeleça o número de pontos de treinamento\n",
    "num_train = 300\n",
    "\n",
    "# Estabeleça o número de pontos de teste\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO: Emabaralhe e distribua o conjunto de dados de acordo com o número de pontos de treinamento e teste abaixo\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X_all, y_all, stratify=y_all, test_size=0.24, random_state=42)\n",
    "\n",
    "# Mostre o resultado da distribuição\n",
    "print \"O conjunto de treinamento tem {} amostras.\".format(X_train.shape[0])\n",
    "print \"O conjunto de teste tem {} amostras.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando Modelos\n",
    "Nesta seção, você irá escolher 3 modelos de aprendizagem supervisionada que sejam apropriados para esse problema e que estejam disponíveis no `scikit-learn`. Primeiro você irá discutir o raciocínio por trás da escolha desses três modelos considerando suas vantagens e desvantagens e o que você sabe sobre os dados. Depois você irá ajustar o modelo a diferentes tamanhos de conjuntos de treinamento (com 100, 200 e 300 pontos) e medir a pontuação F<sub>1</sub>. Você vai precisar preencher três tabelas (uma para cada modelo) que mostrem o tamanho do conjunto de treinamento, o tempo de treinamento, o tempo de previsão e a pontuação F<sub>1</sub> no conjunto de treinamento.\n",
    "\n",
    "**Os seguintes modelos de aprendizagem supervisionada estão atualmente disponíveis no **[`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)** para você escolher:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Árvores de Decisão\n",
    "- Métodos de agregação (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Método do gradiente estocástico (SGDC)\n",
    "- Máquinas de vetores de suporte (SVM)\n",
    "- Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação dos Modelos\n",
    "*Liste três modelos de aprendizagem supervisionada que são apropriadas para esse problema. Para cada modelo escolhido:*\n",
    "- Descreva uma aplicação em mundo real na indústria em que o modelo pode ser aplicado. *(Talvez você precise fazer um pouco de pesquisa para responder essa questão – dê as devidas referências!)* \n",
    "- Quais são as vantagens do modelo; quando ele tem desempenho melhor? \n",
    "- Quais são as desvantagens do modelo, quando ele tem desempenho pior?\n",
    "- O que faz desse modelo um bom candidato para o problema, considerando o que você sabe sobre os dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** \n",
    "1. **Regressão logística:** \n",
    "    + Aplicação da regressão logística no mundo real pode ser utilizado para análise de risco de crédito de consignação, análise espacial de dados arqueológicos, análise de intensão de votos em eleições e etc;\n",
    "    + As vantagens do uso da regressão logística no caso em pauta é o tempo de treinamento pequeno para uma excelente precisão, o uso de linearidade e possui poucos parametros de ajustes;\n",
    "    + As desvantagens da regressão logística são: necessidade de grande amostra de dados para treinamento, usada somente para prever funções discretas (que não desabona no caso em pauta);\n",
    "    + O que faz desse modelo um bom candidato: \n",
    "        - excelente precisão para um tempo de treinamento pequeno.\n",
    "        - trabalha com probabilidade, utiliza função logistica (log-linear), podendo lidar com aspectos não lineares.\n",
    "\n",
    "* **Árvore de Decisão: **\n",
    "    + Aplicação da árvore de decisão no mundo real pode ser utilizado para a identificação de características em biomédica, na área médica para diagnóstico, classificação de texto médico, em astronomia para classificação de estrelas de imagens geradas pelo telescópio espacial Hubble e etc;\n",
    "    + As vantagens do uso da árvore de decisão para o caso em pauta é a capacidade de lidar com dados, tanto numéricas e categóricas, o uso de linearidade, tempo de treinamento moderado para uma excelente precisão, possíbilidade de validar um modelo usando testes estatísticos, torna simples de entender e interpretar o modelo, podendo ser visualizado e o custo de utilização da árvore (isto é, a previsão de dados) é logarítmica no número de pontos de dados utilizado para formar a árvore;.\n",
    "    + As desvantagens do uso da árvore de decisão são: a possibilidade de criar árvores tendenciosas se houverem algumas classes dominantes; pode criar árvores complexas, que não generalizam os dados; \n",
    "    + O que faz desse modelo um bom candidato é a excelente precisão para um tempo de predição pequeno.\n",
    "    \n",
    "        * Árvores de descisão foi escolhido porque é um dos algoritimos mais comumente usados, no mundo real ou acadêmico, apresentando as seguintes vantagens de uso: \n",
    "        - flexibilidade - por não assumir nenhuma distribuição para os dados;\n",
    "        - robustez - árvores univariáveis são invariantes a transformações (estritamente) monótonas de variáveis de entrada;\n",
    "        - eficiência - usa uma estratégia de dividir para conquistar sem _backtracking_ e a complexidade de tempo é linear com o número de exemplos.\n",
    "    \n",
    "\n",
    "* **Máquinas de vetores de suporte (SVM): **\n",
    "    + A aplicação da Máquinas de Vetores de Suporte no mundo real pode ser utilizado para reconhecimento de escritos a mão, na área biologica na classificação de proteínas e etc.\n",
    "    + As vantagens do uso da Máquinas de Vetores de Suporte para o caso em pauta é a eficacia em quantidade de dimensionamento elevado, a possibilidade de utilização de kernels, separar classes mais rapidamente e com menos superajuste do que a maioria dos outros algoritmos, além de exigir apenas uma pequena quantidade de memória.\n",
    "    + As desvantagens da Máquinas de Vetores de Suporte são: não fornece diretamente estimativas de probabilidade; se o número de características é muito maior do que o número de amostras, o método é susceptível de dar maus resultados.\n",
    "    + O que faz desse modelo um bom candidato é busca do limite que separa as classes pela maior margem possível. Quando as duas classes não puderem ser claramente separadas, os algoritmos encontrarão o melhor limite possível.\n",
    "\n",
    "O SVM foi escolhido porque utiliza-se da Teoria de Aprendizado Estatístico (TAE), ou seja, possui uma boa capacidade de generalização, é robusto diante de objetos de grande dimessão e possui caracteristica de convexidade de problema de otimização formulado em seu treinamento, que implica a existência de um único mínimo global. **Além disso, o uso de funções kernel na não linearização das SVMs torna o algoritmo eficiente, pois permite a construção de simples hiperplanos em um espaço de alta dimensão de forma tratável do ponto de vista computacional (Burges, 1998)**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração\n",
    "Execute a célula de código abaixo para inicializar três funções de ajuda que você pode utilizar para treinar e testar os três modelos de aprendizagem supervisionada que você escolheu acima. As funções são as seguintes:\n",
    "- `train_classifier` - recebe como parâmetro um classificador e dados de treinamento e ajusta o classificador aos dados.\n",
    "- `predict_labels` - recebe como parâmetro um classificador ajustado, atributos e rótulo alvo e faz estimativas utilizando a pontuação do F<sub>1</sub>.\n",
    "- `train_predict` - recebe como entrada um classificador, e dados de treinamento e teste, e executa `train_clasifier` e `predict_labels`.\n",
    " - Essa função vai dar a pontuação F<sub>1</sub> tanto para os dados de treinamento como para os de teste, separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@autojit\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Ajusta um classificador para os dados de treinamento. '''\n",
    "    \n",
    "    # Inicia o relógio, treina o classificador e, então, para o relógio\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    print \"O modelo foi treinado em {:.4f} segundos\".format(end - start)\n",
    "\n",
    "@autojit    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Faz uma estimativa utilizando um classificador ajustado baseado na pontuação F1. '''\n",
    "    \n",
    "    # Inicia o relógio, faz estimativas e, então, o relógio para\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados de retorno\n",
    "    print \"As previsões foram feitas em {:.4f} segundos.\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "@autojit\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Treina e faz estimativas utilizando um classificador baseado na pontuação do F1. '''\n",
    "    \n",
    "    # Indica o tamanho do classificador e do conjunto de treinamento\n",
    "    print \"Treinando um {} com {} pontos de treinamento. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Treina o classificador\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Imprime os resultados das estimativas de ambos treinamento e teste\n",
    "    print \"Pontuação F1 para o conjunto de treino: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"Pontuação F1 para o conjunto de teste: {:.4f}.\".format(predict_labels(clf, X_test, y_test))\n",
    "\n",
    "@autojit    \n",
    "def pl_plot(clf, features, target):\n",
    "    y_pred = clf.predict(features)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "@autojit\n",
    "def tc_plot(clf, X_train, y_train):\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Métricas de Desempenho do Modelo\n",
    "Com as funções acima, você vai importar os três modelos de aprendizagem supervisionada de sua escolha e executar a função `train_prediction` para cada um deles. Lembre-se de que você vai precisar treinar e usar cada classificador para três diferentes tamanhos de conjuntos de treinamentos: 100, 200 e 300 pontos. Então você deve ter 9 saídas diferentes abaixo – 3 para cada modelo utilizando cada tamanho de conjunto de treinamento. Na célula de código a seguir, você deve implementar o seguinte:\n",
    "- Importe os três modelos de aprendizagem supervisionada que você escolheu na seção anterior.\n",
    "- Inicialize os três modelos e armazene eles em `clf_A`, `clf_B` e `clf_C`.\n",
    " - Defina um `random_state` para cada modelo, se a opção existir.\n",
    " - **Nota:** Utilize as configurações padrão para cada modelo – você vai calibrar um modelo específico em uma seção posterior.\n",
    "- Crie diferentes tamanhos de conjuntos de treinamento para treinar cada modelo.\n",
    " - *Não embaralhe e distribua novamente os dados! Os novos pontos de treinamento devem ser tirados de `X_train` e `y_train`.*\n",
    "- Treine cada modelo com cada tamanho de conjunto de treinamento e faça estimativas com o conjunto de teste (9 vezes no total).  \n",
    "**Nota:** Três tabelas são fornecidas depois da célula de código a seguir, nas quais você deve anotar seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiolenine/anaconda/lib/python2.7/site-packages/numba/dataflow.py:351: RuntimeWarning: Python2 style print partially supported.  Please use Python3 style print.\n",
      "  \"Python3 style print.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando um LogisticRegression com 100 pontos de treinamento. . .\n",
      "\n",
      "O modelo foi treinado em 0.0456 segundos\n",
      "\n",
      "As previsões foram feitas em 0.0024 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de treino: 0.8671.\n",
      "\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de teste: 0.7068.\n",
      "\n",
      "Treinando um LogisticRegression com 200 pontos de treinamento. . .\n",
      "\n",
      "O modelo foi treinado em 0.0041 segundos\n",
      "\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de treino: 0.8211.\n",
      "\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de teste: 0.7391.\n",
      "\n",
      "Treinando um LogisticRegression com 300 pontos de treinamento. . .\n",
      "\n",
      "O modelo foi treinado em 0.0051 segundos\n",
      "\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de treino: 0.8512.\n",
      "\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de teste: 0.7500.\n",
      "\n",
      "Treinando um DecisionTreeClassifier com 100 pontos de treinamento. . .\n",
      "\n",
      "O modelo foi treinado em 0.0016 segundos\n",
      "\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de teste: 0.6452.\n",
      "\n",
      "Treinando um DecisionTreeClassifier com 200 pontos de treinamento. . .\n",
      "\n",
      "O modelo foi treinado em 0.0024 segundos\n",
      "\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de teste: 0.7258.\n",
      "\n",
      "Treinando um DecisionTreeClassifier com 300 pontos de treinamento. . .\n",
      "\n",
      "O modelo foi treinado em 0.0041 segundos\n",
      "\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de teste: 0.6838.\n",
      "\n",
      "Treinando um SVC com 100 pontos de treinamento. . .\n",
      "\n",
      "O modelo foi treinado em 0.0026 segundos\n",
      "\n",
      "As previsões foram feitas em 0.0017 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de treino: 0.8354.\n",
      "\n",
      "As previsões foram feitas em 0.0016 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de teste: 0.8025.\n",
      "\n",
      "Treinando um SVC com 200 pontos de treinamento. . .\n",
      "\n",
      "O modelo foi treinado em 0.0077 segundos\n",
      "\n",
      "As previsões foram feitas em 0.0056 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de treino: 0.8431.\n",
      "\n",
      "As previsões foram feitas em 0.0028 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de teste: 0.8105.\n",
      "\n",
      "Treinando um SVC com 300 pontos de treinamento. . .\n",
      "\n",
      "O modelo foi treinado em 0.0153 segundos\n",
      "\n",
      "As previsões foram feitas em 0.0110 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de treino: 0.8664.\n",
      "\n",
      "As previsões foram feitas em 0.0036 segundos.\n",
      "\n",
      "Pontuação F1 para o conjunto de teste: 0.8052.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe os três modelos de aprendizagem supervisionada do sklearn\n",
    "# from sklearn import model_A\n",
    "# from sklearn import model_B\n",
    "# from skearln import model_C\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "clf_A = LogisticRegression(random_state = 42)\n",
    "clf_B = DecisionTreeClassifier(random_state = 42)\n",
    "clf_C = SVC(random_state = 42)\n",
    "\n",
    "# TODO: Configure os tamanho dos conjuntos de treinamento\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "\n",
    "    # tamanhos das amostras\n",
    "    for n in [100, 200, 300]:\n",
    "\n",
    "        # TODO: gerar dados de treinamento ao recolher os primeiros 100 pontos de X_train, assim com os primeiros 200, e finalmente todos os 300 pontos\n",
    "        train_predict(clf, X_train[:n], y_train[:n], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Tabulados\n",
    "Edite a célula abaixo e veja como a tabela pode ser desenhada em [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables). Você deve salvar seus resultados abaixo nas tabelas fornecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classificador 1 - LogisticRegression**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                | 0.0036               | 0.0004                      | 0.8671                      | 0.7068               |\n",
    "| 200                                | 0.0037               | 0.0004                      | 0.8211                      | 0.7391               |\n",
    "| 300                                | 0.0047               | 0.0003                      | 0.8512                     | 0.7500               |\n",
    "\n",
    "** Classificador 2 - DecisionTree**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                | 0.0014               | 0.0003                      | 1.0000                      | 0.6452               |\n",
    "| 200                                | 0.0022               | 0.0004                      | 1.0000                      | 0.7258               |\n",
    "| 300                                | 0.0029               | 0.0004                      | 1.0000                      | 0.6838               |\n",
    "\n",
    "** Classificador 3 - SVM**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                | 0.0022               | 0.0013                      | 0.8354                      | 0.8025               |\n",
    "| 200                                | 0.0057               | 0.0020                      | 0.8431                      | 0.8105               |\n",
    "| 300                                | 0.0132               | 0.0030                      | 0.8664                      | 0.8052               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMQGxhGGMMSYg/wdtleDbcaJFWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f0b3a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de F1 para:\n",
      "Logistic Regression : 0.7383\n",
      "Decision tree : 0.7026\n",
      "SVM : 0.8016\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Define quantos passos de treinamento iremos avaliar.\n",
    "step_size = 10\n",
    "\n",
    "#Método que é responsável por resgatar o índice F1 de cada classificador para diferentes tamanhos de amostra\n",
    "@autojit\n",
    "def get_F1(clf, training_set_size):\n",
    "        X_train_sample = X_train[:training_set_size]\n",
    "        y_train_sample = y_train[:training_set_size]\n",
    "        tc_plot(clf, X_train_sample, y_train_sample)\n",
    "        return pl_plot(clf, X_test, y_test)\n",
    "\n",
    "#Aqui criamos uma lista com todos os resultados de F1 para cada um dos classificadores    \n",
    "f1_list_all = []\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    f1_list = []\n",
    "    for training_set_size in range(10,301,step_size):\n",
    "        f1_list.append(get_F1(clf, training_set_size))\n",
    "    f1_list_all.append(f1_list)\n",
    "\n",
    "#Aqui geramos um gráfico que irá nos revelar a evolução do F1 de cada classificador\n",
    "plt.plot(range(10,301,step_size), f1_list_all[0], label='Logistic Regression')\n",
    "plt.plot(range(10,301,step_size), f1_list_all[1], label='Decision tree')\n",
    "plt.plot(range(10,301,step_size), f1_list_all[2], label='SVM')\n",
    "\n",
    "#Configurando eixos \n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('F1 score')\n",
    "plt.legend(loc=4)  \n",
    "\n",
    "#gerando grafico \n",
    "plt.show()\n",
    "\n",
    "print 'Média de F1 para:'\n",
    "print 'Logistic Regression : {:.4f}'.format(np.mean(f1_list_all[0]))\n",
    "print 'Decision tree : {:.4f}'.format(np.mean(f1_list_all[1]))\n",
    "print 'SVM : {:.4f}'.format(np.mean(f1_list_all[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o Melhor Modelo\n",
    "Nesta seção final, você irá escolher dos três modelos de aprendizagem supervisionada o *melhor* para utilizar os dados dos estudantes. Você então executará um busca em matriz otimizada para o modelo em todo o conjunto de treinamento (`X_train` e `y_train`) ao calibrar pelo menos um parâmetro, melhorando em comparação a pontuação F<sub>1</sub> do modelo não calibrado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o Melhor Modelo\n",
    "*Baseando-se nos experimentos que você executou até agora, explique em um ou dois parágrafos ao conselho de supervisores qual modelo que você escolheu como o melhor. Qual modelo é o mais apropriado baseado nos dados disponíveis, recursos limitados, custo e desempenho?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** Podemos verificar que os modelos que tiveram os melhores desempenhos de treinamentos foram respectivamente: SVM > Logit Regression > Decision Tree, conforme ficou demonstrado no gráfico acima. No requisito de custo de treinamento e predição o modelo Regressão Logística teve melhor desempenho, conforme tabela acima exposta. Por enquanto,\n",
    "o melhor desempenho de predição foi do modelo SVM. Destarte, iremos utilizar nas proximas etapas os dois modelos e verificaremos novamente o desempenho após a calibração e normalização.\n",
    "Conforme podemos observar, no gráfico acima, o algoritmo SVM possui melhor estabilidade no F1 Score, quando comparado a Regressão Logística e a Árvores de Decisão, ao evoluir na quantidade de registros usado para o treinamento. E destacamos também as médias do F1 dos algoritmos para a escolha do SVM.\n",
    "\n",
    "**Média de F1 para:**\n",
    "\n",
    "**_SVM : 0.8016_**\n",
    "\n",
    "Logistic Regression : 0.7383\n",
    "\n",
    "Decision tree : 0.7026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 – O Modelo para um Leigo\n",
    "*Em um ou dois parágrafos, explique para o conselho de supervisores, utilizando termos leigos, como o modelo final escolhido deve trabalhar. Tenha certeza que você esteja descrevendo as melhores qualidades do modelo, por exemplo, como o modelo é treinado e como ele faz uma estimativa. Evite jargões técnicos ou matemáticos, como descrever equações ou discutir a implementação do algoritmo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** O nosso objetivo é identificar como melhor classificar os dois grupos de alunos, os que aprovam e os que reprovam, utilizando para isso as características dos alunos. \n",
    "\n",
    "O algoritmo SVM (Support Vector Machine), que escolhemos, funcionará da seguinte forma:\n",
    "\n",
    "1 - Das linhas traçadas identificar a linha que melhor separou os grupos, no gráfico de exemplo abaixo, a melhor linha foi a B;\n",
    "![Traçando linhas com SVM](https://www.analyticsvidhya.com/wp-content/uploads/2015/10/SVM_21.png)\n",
    "\n",
    "2 - Nesse momento a linha será ajustada deixando um margem igual de ambos os lados, para identificar essas margens serão realizados cálculos de distância dos pontos dos grupos mais próximos as linhas de suporte (pontilhadas), conforme o gráfico de exemplo abaixo, posicionando a linha (constante) de forma centralizada entre as linhas de suporte (pontilhadas), de uma forma que a torne mais robusta na separação dos grupos;\n",
    "![Ajustando as Margens do SVM](https://camo.githubusercontent.com/ae3d247a4c7cf5bc9f4134a1a90c0df69b39e988/68747470733a2f2f7777772e64747265672e636f6d2f75706c6f616465642f70616765696d672f53766d4d617267696e322e6a7067)\n",
    "\n",
    "3 - Uma vez determinada a melhor posição da linha reta (de tal forma que as distâncias do pronto mais proximo de cada um dos dois grupos sejam mais distantes), podemos submeter características de alunos não classificados e obter a informação de que grupo ele está mais propenso (dependendo de onde os dados de teste caíram de cada lado da linha), alunos que aprovam ou reprovam.\n",
    "\n",
    "No item dois, comentei sobre as linhas (pontilhadas), esses são os vetores de suporte de um Support Vector Machine, e podemos perceber que eles são importantes para encontrar as melhores margens da linha classificatória entre os grupos.\n",
    "\n",
    "Para os dados que não são lineares, como por exemplo os gráficos abaixo, o SVM pode eficientemente realizar uma classificação não-linear, usando funções matemáticas (kernel) que elevam o espaço de entrada dimensional abaixo para espaço dimensional alto. \n",
    "![SVM não linear](https://www.analyticsvidhya.com/wp-content/uploads/2015/10/SVM_8.png)\n",
    "![SVM não linear transformado em linear](https://www.analyticsvidhya.com/wp-content/uploads/2015/10/SVM_9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Calibrando o Modelo\n",
    "Calibre o modelo escolhido. Utilize busca em matriz (`GridSearchCV`) com, pelo menos, um parâmetro importante calibrado com, pelo menos, 3 valores diferentes. Você vai precisar utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você deve implementar o seguinte:\n",
    "- Importe [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Crie o dicionário de parâmetros que você deseja calibrar para o modelo escolhido.\n",
    " - Examplo: `parameters = {'parameter' : [list of values]}`.\n",
    "- Inicialize o classificador que você escolheu e armazene-o em `clf`.\n",
    "- Crie a função de pontuação F<sub>1</sub> utilizando `make_scorer` e armazene-o em `f1_scorer`.\n",
    " - Estabeleça o parâmetro `pos_label` para o valor correto!\n",
    "- Execute uma busca em matriz no classificador `clf` utilizando o `f1_scorer` como método de pontuação e armazene-o em `grid_obj`.\n",
    "- Treine o objeto de busca em matriz com os dados de treinamento (`X_train`, `y_train`) e armazene-o em `grid_obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 300, 'gamma': 0.001}\n",
      "As previsões foram feitas em 0.0090 segundos.\n",
      "\n",
      "O modelo calibrado tem F1 de 0.9009 no conjunto de treinamento.\n",
      "As previsões foram feitas em 0.0030 segundos.\n",
      "\n",
      "O modelo calibrado tem F1 de 0.7391 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "clf_SVM = SVC()\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"yes\")\n",
    "\n",
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar\n",
    "# C_range = np.logspace(-2, 8, 11)\n",
    "###\n",
    "# Não foi possível utilizar o C_range, no desenvolvimento do projeto por causa da capacidade limitada da minha máquina.\n",
    "###\n",
    "\n",
    "param_grid = [\n",
    "  {\n",
    "    #'C': C_range,\n",
    "   'C': [1, 10, 100, 200, 300, 400, 500],   # Cost - Penalização de elementos dentro da margem de suporte\n",
    "   'gamma': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6], # Gamma - (parâmetro do kernel) Ajusta como dois pontos devem ser considerados semelhantes\n",
    "   'kernel': ['linear','rbf'],              # Kernel - Define a função de custo que será minimizada\n",
    "  }\n",
    " ]\n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "cv = StratifiedShuffleSplit(y_train, random_state=42)\n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj_SVM = grid_search.GridSearchCV(clf_SVM, param_grid,cv=cv,scoring = f1_scorer)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj_SVM.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "print grid_obj_SVM.best_params_\n",
    "reg = grid_obj_SVM.best_estimator_\n",
    "\n",
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetrosprint \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(predict_labels(reg, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(predict_labels(reg, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== com Normalização ==================================================\n",
      "{'kernel': 'rbf', 'C': 300, 'gamma': 0.001}\n",
      "As previsões foram feitas em 0.0118 segundos.\n",
      "\n",
      "O modelo calibrado tem F1 de 0.8024 no conjunto de treinamento.\n",
      "As previsões foram feitas em 0.0029 segundos.\n",
      "\n",
      "O modelo calibrado tem F1 de 0.8050 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "normer = Normalizer()\n",
    "X_train = normer.fit_transform(X_train)\n",
    "X_test = normer.transform(X_test)\n",
    "\n",
    "print \"== com Normalização ==================================================\"\n",
    "print grid_obj_SVM.best_params_\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(predict_labels(reg, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(predict_labels(reg, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEgeGmZklcWCYmVkSB4aZmSX5/5Rf0PlbITa3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111f59050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de F1 para SVM : 0.8050\n"
     ]
    }
   ],
   "source": [
    "f1_list = []\n",
    "for training_set_size in range(10,301,step_size):\n",
    "    f1_list.append(get_F1(clf_SVM, training_set_size))\n",
    "\n",
    "#Aqui geramos um gráfico que irá nos revelar a evolução do F1 de cada classificador\n",
    "plt.plot(range(10,301,step_size), f1_list, label='SVM')\n",
    "\n",
    "#Configurando eixos \n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('F1 score')\n",
    "plt.legend(loc=1)  \n",
    "\n",
    "#gerando grafico \n",
    "plt.show()\n",
    "\n",
    "print 'Média de F1 para SVM : {:.4f}'.format(np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Pontuação F<sub>1</sub> Final\n",
    "*Qual é a pontuação F<sub>1</sub> do modelo final para treinamento e teste? Como ele se compara ao modelo que não foi calibrado?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** Podemos observar, na tabela abaixo, que a pontuação F<sub>1</sub>, do modelo SVM, obteve precisão para treinamentos de 0.8024 e testes de 0.8050. Após a calibração e normalização o modelo SVM, apresentou um crescimento no tempo necessário para processamento do treinamento, porem um pequeno ganho para estimativa. No entanto, melhorou a pontuação do F<sub>1</sub> do teste.\n",
    "\n",
    "| Normalização | Parametro   |Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :----------: | :---------: |:------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| Não          | {'C': 100} | 0.0090              | 0.0030                      | 0.9009                     | 0.7391              |\n",
    "| **Sim**      | {'C': 100} | 0.0118              | **0.0029**                  | 0.8024                     | **0.8050**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você completou todas as implementações de código e respondeu todas as questões acima com êxito, você pode finalizar seu trabalho exportando o iPython Nothebook como um document HTML. Você pode fazer isso utilizando o menu acima e navegando para  \n",
    "**File -> Download as -> HTML (.html)**. Inclua a documentação final junto com o notebook para o envio do seu projeto."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
